{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[0.3836]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([])\n",
      "tensor(0.3799, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.1743,  0.0209,  0.1090,  0.2765, -0.1002, -0.4500,  0.1041,  0.0736,\n",
      "         -0.0140, -0.0630]])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "x = torch.randn(1, 10)\n",
    "w = torch.randn(1, 10, requires_grad=True)\n",
    "\n",
    "o = torch.sigmoid(x@w.t())\n",
    "print(o.shape)\n",
    "print(o)\n",
    "\n",
    "loss = F.mse_loss(torch.ones(1, 1), o)\n",
    "# loss 是个标量\n",
    "print(loss.shape)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "# 得到 loss 分别对 w_0、w_1、...、w_9 的 10 个偏导数\n",
    "print(w.grad)\n",
    "print(w.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0786,  0.4199, -0.7229, -0.4312,  0.1539,  0.1000, -0.2137,  0.3945,\n",
      "         -0.5721, -0.4595]])\n",
      "tensor([[-0.7933, -0.1524,  0.6714, -2.0703, -0.3610, -1.4520, -0.0576, -1.4111,\n",
      "          1.4460,  0.4906],\n",
      "        [-0.4150,  1.5163, -1.5411,  1.9912, -0.6449, -0.6590, -0.1667, -0.6525,\n",
      "         -0.9053,  0.0287]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "# 权重参数矩阵的 10 与输入数据的数量相匹配\n",
    "# 权重参数矩阵的 2 表示 2 组权重参数，也表示中间层有 2 个结果\n",
    "w = torch.randn(2, 10, requires_grad=True)\n",
    "print(x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[0.3547, 0.8111]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# [1, 10] @ [10, 2] --> [1, 2]\n",
    "o = torch.sigmoid(x@w.t())\n",
    "print(o.shape)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2261, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17107\\AppData\\Local\\Temp\\ipykernel_32336\\474751592.py:4: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(torch.ones(1, 1), o)\n"
     ]
    }
   ],
   "source": [
    "# 这里使用 torch.ones(1, 2) 更为合适\n",
    "# torch.ones(1, 1) 原本是不能与 [1, 2] 进行计算的\n",
    "# 但是有广播机制，自动将 [1, 1] 广播为 [1, 2]， 从而使得二者可以进行计算\n",
    "loss = F.mse_loss(torch.ones(1, 1), o)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1593, -0.0620,  0.1068,  0.0637, -0.0227, -0.0148,  0.0316, -0.0583,\n",
      "          0.0845,  0.0679],\n",
      "        [ 0.0312, -0.0121,  0.0209,  0.0125, -0.0045, -0.0029,  0.0062, -0.0114,\n",
      "          0.0166,  0.0133]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "# 权重参数更新 w' = w - learningrate * w.grad\n",
    "# 所以 w 、w'、 w.grad 的形状是一样的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
